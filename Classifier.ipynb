{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78ec5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8666b593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the dataset\n",
    "df = pd.read_csv('data2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9697a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns\n",
    "df = df.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c5886d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>6.981</td>\n",
       "      <td>28.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>9.71</td>\n",
       "      <td>39.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>43.79</td>\n",
       "      <td>188.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>143.5</td>\n",
       "      <td>2501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.1634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  Minimum Maximum\n",
       "0      radius_mean    6.981   28.11\n",
       "1     texture_mean     9.71   39.28\n",
       "2   perimeter_mean    43.79   188.5\n",
       "3        area_mean    143.5  2501.0\n",
       "4  smoothness_mean  0.05263  0.1634"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the minimum and maximum values\n",
    "\n",
    "minimum = df.min()\n",
    "minimum = minimum.drop('diagnosis', axis = 0)\n",
    "\n",
    "maximum = df.max()\n",
    "maximum = maximum.drop('diagnosis', axis = 0)\n",
    "\n",
    "minmax = pd.concat([minimum, maximum], axis = 1).reset_index()\n",
    "minmax.rename(columns = {0:'Minimum', 1:'Maximum'}, inplace = True)\n",
    "minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dff1e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>population_min</th>\n",
       "      <th>population_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>5.5848</td>\n",
       "      <td>33.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>7.768</td>\n",
       "      <td>47.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>35.032</td>\n",
       "      <td>226.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>114.8</td>\n",
       "      <td>3001.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.19608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index population_min population_max\n",
       "0      radius_mean         5.5848         33.732\n",
       "1     texture_mean          7.768         47.136\n",
       "2   perimeter_mean         35.032          226.2\n",
       "3        area_mean          114.8         3001.2\n",
       "4  smoothness_mean       0.042104        0.19608"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the population ranges\n",
    "\n",
    "minmax2 = minmax[\"Minimum\"] = 0.8 * minmax[\"Minimum\"]\n",
    "minmax3 = minmax[\"Maximum\"] = 1.2 * minmax[\"Maximum\"]\n",
    "\n",
    "normalised = pd.concat([minmax['index'],minmax2, minmax3], axis = 1)\n",
    "\n",
    "normalised.rename(columns = {'Minimum':'population_min' ,'Maximum':'population_max'}, inplace = True)\n",
    "\n",
    "normalised.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b84d98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>population_min</th>\n",
       "      <th>Minimum_value</th>\n",
       "      <th>Maximum_value</th>\n",
       "      <th>population_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>5.5848</td>\n",
       "      <td>6.981</td>\n",
       "      <td>28.11</td>\n",
       "      <td>33.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>7.768</td>\n",
       "      <td>9.71</td>\n",
       "      <td>39.28</td>\n",
       "      <td>47.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>35.032</td>\n",
       "      <td>43.79</td>\n",
       "      <td>188.5</td>\n",
       "      <td>226.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>114.8</td>\n",
       "      <td>143.5</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>3001.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.19608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.41448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.51216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.24144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.039968</td>\n",
       "      <td>0.04996</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.116928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index population_min Minimum_value Maximum_value  \\\n",
       "0             radius_mean         5.5848         6.981         28.11   \n",
       "1            texture_mean          7.768          9.71         39.28   \n",
       "2          perimeter_mean         35.032         43.79         188.5   \n",
       "3               area_mean          114.8         143.5        2501.0   \n",
       "4         smoothness_mean       0.042104       0.05263        0.1634   \n",
       "5        compactness_mean       0.015504       0.01938        0.3454   \n",
       "6          concavity_mean            0.0           0.0        0.4268   \n",
       "7     concave points_mean            0.0           0.0        0.2012   \n",
       "8           symmetry_mean         0.0848         0.106         0.304   \n",
       "9  fractal_dimension_mean       0.039968       0.04996       0.09744   \n",
       "\n",
       "  population_max  \n",
       "0         33.732  \n",
       "1         47.136  \n",
       "2          226.2  \n",
       "3         3001.2  \n",
       "4        0.19608  \n",
       "5        0.41448  \n",
       "6        0.51216  \n",
       "7        0.24144  \n",
       "8         0.3648  \n",
       "9       0.116928  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the above two dataframes\n",
    " \n",
    "new = pd.concat([minimum, maximum], axis = 1).reset_index()\n",
    "\n",
    "normalised_finish = pd.concat([normalised['index'],normalised['population_min'], new[0], new[1], normalised['population_max']], axis = 1).reset_index()\n",
    "\n",
    "normalised_finish.rename(columns = {0:'Minimum_value', 1:'Maximum_value'}, inplace = True)\n",
    "\n",
    "normalised_finish = normalised_finish.drop('level_0', axis = 1)\n",
    "\n",
    "\n",
    "normalised_finish.head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbf91def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440722</td>\n",
       "      <td>0.066348</td>\n",
       "      <td>0.459114</td>\n",
       "      <td>0.307026</td>\n",
       "      <td>0.495506</td>\n",
       "      <td>0.656922</td>\n",
       "      <td>0.585950</td>\n",
       "      <td>0.609261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515825</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>3.511479</td>\n",
       "      <td>0.377441</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.515936</td>\n",
       "      <td>0.473842</td>\n",
       "      <td>0.760023</td>\n",
       "      <td>0.498838</td>\n",
       "      <td>0.365267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>0.532384</td>\n",
       "      <td>0.254064</td>\n",
       "      <td>0.511948</td>\n",
       "      <td>0.419623</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.158245</td>\n",
       "      <td>0.169674</td>\n",
       "      <td>0.290631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505257</td>\n",
       "      <td>0.276810</td>\n",
       "      <td>2.993739</td>\n",
       "      <td>0.364731</td>\n",
       "      <td>0.318121</td>\n",
       "      <td>0.132050</td>\n",
       "      <td>0.160809</td>\n",
       "      <td>0.532646</td>\n",
       "      <td>0.223129</td>\n",
       "      <td>0.219488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>0.501119</td>\n",
       "      <td>0.342461</td>\n",
       "      <td>0.496778</td>\n",
       "      <td>0.377009</td>\n",
       "      <td>0.438354</td>\n",
       "      <td>0.361917</td>\n",
       "      <td>0.385426</td>\n",
       "      <td>0.529738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.319353</td>\n",
       "      <td>2.867314</td>\n",
       "      <td>0.314899</td>\n",
       "      <td>0.416131</td>\n",
       "      <td>0.322711</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.695876</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>0.212462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>0.207305</td>\n",
       "      <td>0.320362</td>\n",
       "      <td>0.222569</td>\n",
       "      <td>0.093993</td>\n",
       "      <td>0.652024</td>\n",
       "      <td>0.672712</td>\n",
       "      <td>0.471337</td>\n",
       "      <td>0.435719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232116</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>1.791098</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>0.727287</td>\n",
       "      <td>0.676783</td>\n",
       "      <td>0.457202</td>\n",
       "      <td>0.737400</td>\n",
       "      <td>0.802252</td>\n",
       "      <td>0.629210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>0.522436</td>\n",
       "      <td>0.166938</td>\n",
       "      <td>0.523456</td>\n",
       "      <td>0.409576</td>\n",
       "      <td>0.377955</td>\n",
       "      <td>0.293993</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>0.431991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438868</td>\n",
       "      <td>0.141556</td>\n",
       "      <td>2.861294</td>\n",
       "      <td>0.287864</td>\n",
       "      <td>0.382826</td>\n",
       "      <td>0.146797</td>\n",
       "      <td>0.266241</td>\n",
       "      <td>0.465349</td>\n",
       "      <td>0.165634</td>\n",
       "      <td>0.159771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>0.567556</td>\n",
       "      <td>0.371418</td>\n",
       "      <td>0.559550</td>\n",
       "      <td>0.472630</td>\n",
       "      <td>0.447446</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.575298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517722</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>3.140231</td>\n",
       "      <td>0.379055</td>\n",
       "      <td>0.399954</td>\n",
       "      <td>0.151846</td>\n",
       "      <td>0.273363</td>\n",
       "      <td>0.634593</td>\n",
       "      <td>0.120353</td>\n",
       "      <td>0.132304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>0.516751</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.503055</td>\n",
       "      <td>0.397104</td>\n",
       "      <td>0.361719</td>\n",
       "      <td>0.220304</td>\n",
       "      <td>0.281162</td>\n",
       "      <td>0.405525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>0.574611</td>\n",
       "      <td>2.917483</td>\n",
       "      <td>0.319337</td>\n",
       "      <td>0.283866</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>0.213991</td>\n",
       "      <td>0.466208</td>\n",
       "      <td>0.196616</td>\n",
       "      <td>0.108983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>0.391338</td>\n",
       "      <td>0.515952</td>\n",
       "      <td>0.383265</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.275666</td>\n",
       "      <td>0.217547</td>\n",
       "      <td>0.180627</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342402</td>\n",
       "      <td>0.491732</td>\n",
       "      <td>2.349575</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0.271020</td>\n",
       "      <td>0.230466</td>\n",
       "      <td>0.226504</td>\n",
       "      <td>0.406071</td>\n",
       "      <td>0.143887</td>\n",
       "      <td>0.166699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>0.533449</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>0.549611</td>\n",
       "      <td>0.398489</td>\n",
       "      <td>0.491609</td>\n",
       "      <td>0.655418</td>\n",
       "      <td>0.686114</td>\n",
       "      <td>0.629556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525580</td>\n",
       "      <td>0.598090</td>\n",
       "      <td>3.511479</td>\n",
       "      <td>0.337495</td>\n",
       "      <td>0.514140</td>\n",
       "      <td>0.678225</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.758877</td>\n",
       "      <td>0.422277</td>\n",
       "      <td>0.390149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.426031</td>\n",
       "      <td>0.067417</td>\n",
       "      <td>0.022935</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>0.416479</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>0.024299</td>\n",
       "      <td>0.157119</td>\n",
       "      <td>0.034147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241152</td>\n",
       "      <td>0.128596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M     0.440722      0.066348        0.459114   0.307026   \n",
       "1      842517         M     0.532384      0.254064        0.511948   0.419623   \n",
       "2    84300903         M     0.501119      0.342461        0.496778   0.377009   \n",
       "3    84348301         M     0.207305      0.320362        0.222569   0.093993   \n",
       "4    84358402         M     0.522436      0.166938        0.523456   0.409576   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M     0.567556      0.371418        0.559550   0.472630   \n",
       "565    926682         M     0.516751      0.520270        0.503055   0.397104   \n",
       "566    926954         M     0.391338      0.515952        0.383265   0.257518   \n",
       "567    927241         M     0.533449      0.547704        0.549611   0.398489   \n",
       "568     92751         B     0.077273      0.426031        0.067417   0.022935   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.495506          0.656922        0.585950             0.609261   \n",
       "1           0.276900          0.158245        0.169674             0.290631   \n",
       "2           0.438354          0.361917        0.385426             0.529738   \n",
       "3           0.652024          0.672712        0.471337             0.435719   \n",
       "4           0.377955          0.293993        0.386598             0.431991   \n",
       "..               ...               ...             ...                  ...   \n",
       "564         0.447446          0.251634        0.476218             0.575298   \n",
       "565         0.361719          0.220304        0.281162             0.405525   \n",
       "566         0.275666          0.217547        0.180627             0.219599   \n",
       "567         0.491609          0.655418        0.686114             0.629556   \n",
       "568         0.068361          0.070470        0.000000             0.000000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...      0.515825       0.154800         3.511479    0.377441   \n",
       "1    ...      0.505257       0.276810         2.993739    0.364731   \n",
       "2    ...      0.466779       0.319353         2.867314    0.314899   \n",
       "3    ...      0.232116       0.338818         1.791098    0.084642   \n",
       "4    ...      0.438868       0.141556         2.861294    0.287864   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...      0.517722       0.336812         3.140231    0.379055   \n",
       "565  ...      0.470030       0.574611         2.917483    0.319337   \n",
       "566  ...      0.342402       0.491732         2.349575    0.196875   \n",
       "567  ...      0.525580       0.598090         3.511479    0.337495   \n",
       "568  ...      0.084327       0.416479         0.994221    0.024299   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0            0.500818           0.515936         0.473842   \n",
       "1            0.318121           0.132050         0.160809   \n",
       "2            0.416131           0.322711         0.299787   \n",
       "3            0.727287           0.676783         0.457202   \n",
       "4            0.382826           0.146797         0.266241   \n",
       "..                ...                ...              ...   \n",
       "564          0.399954           0.151846         0.273363   \n",
       "565          0.283866           0.136538         0.213991   \n",
       "566          0.271020           0.230466         0.226504   \n",
       "567          0.514140           0.678225         0.624800   \n",
       "568          0.157119           0.034147         0.000000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.760023        0.498838                 0.365267  \n",
       "1                0.532646        0.223129                 0.219488  \n",
       "2                0.695876        0.351674                 0.212462  \n",
       "3                0.737400        0.802252                 0.629210  \n",
       "4                0.465349        0.165634                 0.159771  \n",
       "..                    ...             ...                      ...  \n",
       "564              0.634593        0.120353                 0.132304  \n",
       "565              0.466208        0.196616                 0.108983  \n",
       "566              0.406071        0.143887                 0.166699  \n",
       "567              0.758877        0.422277                 0.390149  \n",
       "568              0.000000        0.241152                 0.128596  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the normalised dataset created in Excel\n",
    "\n",
    "data =pd.read_csv('data.csv')\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46c0fd8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.440722</td>\n",
       "      <td>0.066348</td>\n",
       "      <td>0.459114</td>\n",
       "      <td>0.307026</td>\n",
       "      <td>0.495506</td>\n",
       "      <td>0.656922</td>\n",
       "      <td>0.585950</td>\n",
       "      <td>0.609261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515825</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>3.511479</td>\n",
       "      <td>0.377441</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.515936</td>\n",
       "      <td>0.473842</td>\n",
       "      <td>0.760023</td>\n",
       "      <td>0.498838</td>\n",
       "      <td>0.365267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532384</td>\n",
       "      <td>0.254064</td>\n",
       "      <td>0.511948</td>\n",
       "      <td>0.419623</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.158245</td>\n",
       "      <td>0.169674</td>\n",
       "      <td>0.290631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505257</td>\n",
       "      <td>0.276810</td>\n",
       "      <td>2.993739</td>\n",
       "      <td>0.364731</td>\n",
       "      <td>0.318121</td>\n",
       "      <td>0.132050</td>\n",
       "      <td>0.160809</td>\n",
       "      <td>0.532646</td>\n",
       "      <td>0.223129</td>\n",
       "      <td>0.219488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501119</td>\n",
       "      <td>0.342461</td>\n",
       "      <td>0.496778</td>\n",
       "      <td>0.377009</td>\n",
       "      <td>0.438354</td>\n",
       "      <td>0.361917</td>\n",
       "      <td>0.385426</td>\n",
       "      <td>0.529738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.319353</td>\n",
       "      <td>2.867314</td>\n",
       "      <td>0.314899</td>\n",
       "      <td>0.416131</td>\n",
       "      <td>0.322711</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.695876</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>0.212462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207305</td>\n",
       "      <td>0.320362</td>\n",
       "      <td>0.222569</td>\n",
       "      <td>0.093993</td>\n",
       "      <td>0.652024</td>\n",
       "      <td>0.672712</td>\n",
       "      <td>0.471337</td>\n",
       "      <td>0.435719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232116</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>1.791098</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>0.727287</td>\n",
       "      <td>0.676783</td>\n",
       "      <td>0.457202</td>\n",
       "      <td>0.737400</td>\n",
       "      <td>0.802252</td>\n",
       "      <td>0.629210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522436</td>\n",
       "      <td>0.166938</td>\n",
       "      <td>0.523456</td>\n",
       "      <td>0.409576</td>\n",
       "      <td>0.377955</td>\n",
       "      <td>0.293993</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>0.431991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438868</td>\n",
       "      <td>0.141556</td>\n",
       "      <td>2.861294</td>\n",
       "      <td>0.287864</td>\n",
       "      <td>0.382826</td>\n",
       "      <td>0.146797</td>\n",
       "      <td>0.266241</td>\n",
       "      <td>0.465349</td>\n",
       "      <td>0.165634</td>\n",
       "      <td>0.159771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567556</td>\n",
       "      <td>0.371418</td>\n",
       "      <td>0.559550</td>\n",
       "      <td>0.472630</td>\n",
       "      <td>0.447446</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.575298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517722</td>\n",
       "      <td>0.336812</td>\n",
       "      <td>3.140231</td>\n",
       "      <td>0.379055</td>\n",
       "      <td>0.399954</td>\n",
       "      <td>0.151846</td>\n",
       "      <td>0.273363</td>\n",
       "      <td>0.634593</td>\n",
       "      <td>0.120353</td>\n",
       "      <td>0.132304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516751</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.503055</td>\n",
       "      <td>0.397104</td>\n",
       "      <td>0.361719</td>\n",
       "      <td>0.220304</td>\n",
       "      <td>0.281162</td>\n",
       "      <td>0.405525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>0.574611</td>\n",
       "      <td>2.917483</td>\n",
       "      <td>0.319337</td>\n",
       "      <td>0.283866</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>0.213991</td>\n",
       "      <td>0.466208</td>\n",
       "      <td>0.196616</td>\n",
       "      <td>0.108983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391338</td>\n",
       "      <td>0.515952</td>\n",
       "      <td>0.383265</td>\n",
       "      <td>0.257518</td>\n",
       "      <td>0.275666</td>\n",
       "      <td>0.217547</td>\n",
       "      <td>0.180627</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342402</td>\n",
       "      <td>0.491732</td>\n",
       "      <td>2.349575</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0.271020</td>\n",
       "      <td>0.230466</td>\n",
       "      <td>0.226504</td>\n",
       "      <td>0.406071</td>\n",
       "      <td>0.143887</td>\n",
       "      <td>0.166699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533449</td>\n",
       "      <td>0.547704</td>\n",
       "      <td>0.549611</td>\n",
       "      <td>0.398489</td>\n",
       "      <td>0.491609</td>\n",
       "      <td>0.655418</td>\n",
       "      <td>0.686114</td>\n",
       "      <td>0.629556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525580</td>\n",
       "      <td>0.598090</td>\n",
       "      <td>3.511479</td>\n",
       "      <td>0.337495</td>\n",
       "      <td>0.514140</td>\n",
       "      <td>0.678225</td>\n",
       "      <td>0.624800</td>\n",
       "      <td>0.758877</td>\n",
       "      <td>0.422277</td>\n",
       "      <td>0.390149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.077273</td>\n",
       "      <td>0.426031</td>\n",
       "      <td>0.067417</td>\n",
       "      <td>0.022935</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>0.416479</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>0.024299</td>\n",
       "      <td>0.157119</td>\n",
       "      <td>0.034147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241152</td>\n",
       "      <td>0.128596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1     0.440722      0.066348        0.459114   \n",
       "1      842517          1     0.532384      0.254064        0.511948   \n",
       "2    84300903          1     0.501119      0.342461        0.496778   \n",
       "3    84348301          1     0.207305      0.320362        0.222569   \n",
       "4    84358402          1     0.522436      0.166938        0.523456   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1     0.567556      0.371418        0.559550   \n",
       "565    926682          1     0.516751      0.520270        0.503055   \n",
       "566    926954          1     0.391338      0.515952        0.383265   \n",
       "567    927241          1     0.533449      0.547704        0.549611   \n",
       "568     92751          0     0.077273      0.426031        0.067417   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     0.307026         0.495506          0.656922        0.585950   \n",
       "1     0.419623         0.276900          0.158245        0.169674   \n",
       "2     0.377009         0.438354          0.361917        0.385426   \n",
       "3     0.093993         0.652024          0.672712        0.471337   \n",
       "4     0.409576         0.377955          0.293993        0.386598   \n",
       "..         ...              ...               ...             ...   \n",
       "564   0.472630         0.447446          0.251634        0.476218   \n",
       "565   0.397104         0.361719          0.220304        0.281162   \n",
       "566   0.257518         0.275666          0.217547        0.180627   \n",
       "567   0.398489         0.491609          0.655418        0.686114   \n",
       "568   0.022935         0.068361          0.070470        0.000000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               0.609261  ...      0.515825       0.154800         3.511479   \n",
       "1               0.290631  ...      0.505257       0.276810         2.993739   \n",
       "2               0.529738  ...      0.466779       0.319353         2.867314   \n",
       "3               0.435719  ...      0.232116       0.338818         1.791098   \n",
       "4               0.431991  ...      0.438868       0.141556         2.861294   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564             0.575298  ...      0.517722       0.336812         3.140231   \n",
       "565             0.405525  ...      0.470030       0.574611         2.917483   \n",
       "566             0.219599  ...      0.342402       0.491732         2.349575   \n",
       "567             0.629556  ...      0.525580       0.598090         3.511479   \n",
       "568             0.000000  ...      0.084327       0.416479         0.994221   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.377441          0.500818           0.515936         0.473842   \n",
       "1      0.364731          0.318121           0.132050         0.160809   \n",
       "2      0.314899          0.416131           0.322711         0.299787   \n",
       "3      0.084642          0.727287           0.676783         0.457202   \n",
       "4      0.287864          0.382826           0.146797         0.266241   \n",
       "..          ...               ...                ...              ...   \n",
       "564    0.379055          0.399954           0.151846         0.273363   \n",
       "565    0.319337          0.283866           0.136538         0.213991   \n",
       "566    0.196875          0.271020           0.230466         0.226504   \n",
       "567    0.337495          0.514140           0.678225         0.624800   \n",
       "568    0.024299          0.157119           0.034147         0.000000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.760023        0.498838                 0.365267  \n",
       "1                0.532646        0.223129                 0.219488  \n",
       "2                0.695876        0.351674                 0.212462  \n",
       "3                0.737400        0.802252                 0.629210  \n",
       "4                0.465349        0.165634                 0.159771  \n",
       "..                    ...             ...                      ...  \n",
       "564              0.634593        0.120353                 0.132304  \n",
       "565              0.466208        0.196616                 0.108983  \n",
       "566              0.406071        0.143887                 0.166699  \n",
       "567              0.758877        0.422277                 0.390149  \n",
       "568              0.000000        0.241152                 0.128596  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maps diagnosis to 0 or 1\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "433b4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splits the dataset, 70% training - 30% testing\n",
    "\n",
    "shuffle_df = data.sample(frac=1)\n",
    "\n",
    "train_size = int(0.7 * len(data))\n",
    "\n",
    "# Split your dataset \n",
    "training = shuffle_df[:train_size]\n",
    "testing = shuffle_df[train_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f85e81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output variables for training and testing\n",
    "\n",
    "X_train = training.iloc[:, 2:].values\n",
    "y_train = training.iloc[:, 1].values\n",
    "\n",
    "X_test = testing.iloc[:, 2:].values\n",
    "y_test = testing.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57643b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network activiation functions\n",
    "def sigmoid(sum):\n",
    "    return 1 / (1 + np.exp(-sum))\n",
    "    \n",
    "def sigmoid_derivative(sigmoid):\n",
    "    return sigmoid * (1 - sigmoid)\n",
    "\n",
    "# Layers and Neurons\n",
    "input_nodes = 30\n",
    "hidden_nodes=15\n",
    "output_nodes = 2\n",
    "\n",
    "# Randomised Weights\n",
    "weight1 = 2*np.random.random((input_nodes, hidden_nodes)) - 1\n",
    "weight2 = 2*np.random.random((hidden_nodes, output_nodes)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19431ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Error: 0.424499378852304\n",
      "Epoch: 1000 Error: 0.06289890261062381\n",
      "Epoch: 2000 Error: 0.04410246584786867\n",
      "Epoch: 3000 Error: 0.03596092139771406\n",
      "Epoch: 4000 Error: 0.03141509369919266\n",
      "Epoch: 5000 Error: 0.027867285585443047\n",
      "Epoch: 6000 Error: 0.025203334102585885\n",
      "Epoch: 7000 Error: 0.02314447640745332\n",
      "Epoch: 8000 Error: 0.02150935046460644\n",
      "Epoch: 9000 Error: 0.02017530692008349\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "epochs=10000\n",
    "\n",
    "y_train = y_train[:,None]\n",
    "\n",
    "train_MSE = []\n",
    "\n",
    "# Iterates through the network as many times as the epoch is set at\n",
    "for i in range(epochs):\n",
    "    \n",
    "#     Forward Propagate    \n",
    "    hidden_layer = sigmoid(np.dot(X_train, weight1))\n",
    "\n",
    "    output_layer = sigmoid(np.dot(hidden_layer, weight2))\n",
    "    \n",
    "#     Back Propagate\n",
    "    error = y_train-output_layer\n",
    "    \n",
    "    derivative_output = sigmoid_derivative(output_layer)\n",
    "    l2_delta = error * derivative_output\n",
    "    \n",
    "    derivative_hidden = sigmoid_derivative(hidden_layer)\n",
    "    l1_delta = l2_delta.dot(weight2.T) * derivative_hidden\n",
    "    \n",
    "    weight2 = np.add(weight2, hidden_layer.T.dot(l2_delta) * learning_rate)\n",
    "    weight1 = np.add(weight1, X_train.T.dot(l1_delta) * learning_rate)\n",
    "\n",
    "#     Error average at every 1000 epoch\n",
    "    error_average = np.mean(abs(error))\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch: ' + str(i + 0 ) + ' Error: ' + str(error_average))\n",
    "        train_MSE.append(error_average)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d6cb4b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "# Forward Propagate\n",
    "sum_synapse1 = np.dot(X_test, weight1)\n",
    "hidden_layer = sigmoid(sum_synapse1) \n",
    "        \n",
    "sum_synapse2 = np.dot(hidden_layer, weight2) \n",
    "output_layer = sigmoid(sum_synapse2)\n",
    "\n",
    "\n",
    "\n",
    "prediction = []\n",
    "correct = 0\n",
    "\n",
    "# Iterate testing the length of the output layer\n",
    "for i in range(171):\n",
    "    \n",
    "#     Track the predictions from the testing\n",
    "    if np.all(output_layer[i] < 0.5):\n",
    "\n",
    "        predict= 0\n",
    "    else:\n",
    "        predict = 1\n",
    "        \n",
    "\n",
    "    if predict != y_test[i]:\n",
    "        \n",
    "        correct += 0\n",
    "    else:\n",
    "        correct += 1\n",
    "        \n",
    "\n",
    "                \n",
    "            \n",
    "    prediction.append(predict)\n",
    "    \n",
    "#     Mean Squared Error from the predication and actual output\n",
    "\n",
    "MeanSquaredError = np.square(y_test - prediction).mean()\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error: \", MeanSquaredError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ea3a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average for mean squared error function\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b1b6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_avg = Average(train_MSE[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "800f0b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.032475237448396824\n",
      "Testing MSE: 0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "print('Training MSE: ' + str(training_avg))\n",
    "print('Testing MSE: ' + str(MeanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4eaa386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE vs Epoch\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE')\n",
    "plt.title('Plot showing results from Neural Network')\n",
    "plt.plot(train_MSE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99edd79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97cf2a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Prediction\n",
       "0        0           0\n",
       "1        0           0\n",
       "2        0           0\n",
       "3        1           1\n",
       "4        1           1\n",
       "5        0           1\n",
       "6        0           0\n",
       "7        0           0\n",
       "8        1           0\n",
       "9        0           0\n",
       "10       0           0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe showing testing predicition vs actual output\n",
    "\n",
    "df_from_arr = pd.DataFrame(data=[y_test, prediction_arr]).T\n",
    "df_from_arr.rename(columns ={0:'Actual', 1: 'Prediction'}, inplace = True)\n",
    "df_from_arr.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01a6ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1\n",
       "Actual            \n",
       "0           83  28\n",
       "1           35  25"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix = pd.crosstab(df_from_arr['Actual'], df_from_arr['Prediction'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a2d19c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83],\n",
       "       [28],\n",
       "       [35],\n",
       "       [25]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array(confusion_matrix)\n",
    "matrix = matrix.reshape(4,1)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9bba786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variable to each position of array above\n",
    "\n",
    "TN = int(matrix[0])\n",
    "FP = int(matrix[1])\n",
    "FN = int(matrix[2])\n",
    "TP = int(matrix[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c79b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance functions for confusion matrix\n",
    "\n",
    "def accuracy(TP,TN,FP,FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "\n",
    "def precision(TP, FP):\n",
    "    return (TP / (TP + FP)) * 100\n",
    "\n",
    "def truePositive(TP, FN):\n",
    "    return (TP / (TP + FN)) * 100\n",
    "\n",
    "def falsePositive(FP, TN):\n",
    "    return (FP / (FP + TN)) * 100\n",
    "\n",
    "def trueNegative(TN,FP):\n",
    "    return (TN / (TN + FP)) * 100\n",
    "\n",
    "def falseNegative(FP,TN):\n",
    "    return (FN / (FN + TP)) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c2d2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 63.1578947368421 %\n",
      "Precision 47.16981132075472%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy and Precision\n",
    "print ('Accuracy ' + str(accuracy(TP, TN, FP, FN)) + ' %')\n",
    "print('Precision ' + str(precision(TP, FP)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b9c104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 41.66666666666667%\n",
      "False Negative Rate: 58.333333333333336%\n",
      "True Negative Rate: 74.77477477477478%\n",
      "False Positive Rate: 25.225225225225223%\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix Performance \n",
    "\n",
    "print('True Positive Rate: ' + str(truePositive(TP, FN)) + '%')\n",
    "print('False Negative Rate: ' + str(falseNegative(FN , FP)) + '%')\n",
    "print('True Negative Rate: ' + str(trueNegative(TN,FP)) + '%')\n",
    "print('False Positive Rate: ' + str(falsePositive(FP, TN)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d468fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 5 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "417b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes2 = 5\n",
    "\n",
    "# Randomised Weights\n",
    "weight1_2 = 2*np.random.random((input_nodes, hidden_nodes2)) - 1\n",
    "weight2_2 = 2*np.random.random((hidden_nodes2, output_nodes)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ab34eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Error: 0.49799877164819695\n",
      "Epoch: 1000 Error: 0.07407142722307658\n",
      "Epoch: 2000 Error: 0.05000732577236908\n",
      "Epoch: 3000 Error: 0.038510234665793466\n",
      "Epoch: 4000 Error: 0.03225530898444782\n",
      "Epoch: 5000 Error: 0.028291223131412663\n",
      "Epoch: 6000 Error: 0.02545503589744218\n",
      "Epoch: 7000 Error: 0.023323571917564654\n",
      "Epoch: 8000 Error: 0.021649481826806538\n",
      "Epoch: 9000 Error: 0.020285172471154352\n"
     ]
    }
   ],
   "source": [
    "train_MSE2 = []\n",
    "\n",
    "# Iterates through the network as many times as the epoch is set at\n",
    "for i in range(epochs):\n",
    "    \n",
    "#     Forward Propagate\n",
    "    sum_synapse1 = np.dot(X_train, weight1_2)\n",
    "    hidden_layer2 = sigmoid(sum_synapse1)\n",
    "        \n",
    "    sum_synapse2 = np.dot(hidden_layer2, weight2_2) \n",
    "    output_layer2 = sigmoid(sum_synapse2)\n",
    "    \n",
    "#     Back Propagate\n",
    "    error = y_train-output_layer2\n",
    "    \n",
    "    derivative_output = sigmoid_derivative(output_layer2)\n",
    "    l2_delta = error * derivative_output\n",
    "    \n",
    "    derivative_hidden = sigmoid_derivative(hidden_layer2)\n",
    "    l1_delta = l2_delta.dot(weight2_2.T) * derivative_hidden\n",
    "    \n",
    "    weight2_2 = np.add(weight2_2, hidden_layer2.T.dot(l2_delta) * learning_rate)\n",
    "    weight1_2 = np.add(weight1_2, X_train.T.dot(l1_delta) * learning_rate)\n",
    "    \n",
    "#     Error and epoch\n",
    "    \n",
    "    error_average = np.mean(abs(error))\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch: ' + str(i + 0 ) + ' Error: ' + str(error_average))\n",
    "        train_MSE2.append(error_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8068c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.05263157894736842\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "prediction2 = []\n",
    "correct2 = 0\n",
    "\n",
    "# Forward Propagate\n",
    "\n",
    "sum_synapse1 = np.dot(X_test, weight1_2)\n",
    "hidden_layer2 = sigmoid(sum_synapse1) \n",
    "        \n",
    "sum_synapse2 = np.dot(hidden_layer2, weight2_2) \n",
    "output_layer2 = sigmoid(sum_synapse2)\n",
    "\n",
    "for i in range(171):\n",
    "    \n",
    "# Prediction\n",
    "    if np.all(output_layer2[i]  >= 0.5):\n",
    "\n",
    "        predict= 1\n",
    "    else:\n",
    "        predict = 0\n",
    "\n",
    "    if predict != y_test[i]:\n",
    "        \n",
    "        correct2 += 0\n",
    "    else:\n",
    "        \n",
    "        correct2 +=1\n",
    "        \n",
    "    prediction2.append(predict)\n",
    "\n",
    "MeanSquaredError2 = np.square(y_test - prediction2).mean()\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error: \", MeanSquaredError2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "beee3ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE vs Epoch\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE')\n",
    "plt.title('Plot showing results from Neural Network')\n",
    "plt.plot(train_MSE2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d641597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_arr2 = np.array(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f802dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Prediction\n",
       "0        0           0\n",
       "1        0           0\n",
       "2        0           0\n",
       "3        1           1\n",
       "4        1           1\n",
       "5        0           0\n",
       "6        0           0\n",
       "7        0           0\n",
       "8        1           1\n",
       "9        0           0\n",
       "10       0           0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predition vs Actual output\n",
    "df_from_arr2 = pd.DataFrame(data=[y_test, prediction_arr2]).T\n",
    "df_from_arr2.rename(columns ={0:'Actual', 1: 'Prediction'}, inplace = True)\n",
    "df_from_arr2.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "61807de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction    0   1\n",
       "Actual             \n",
       "0           108   3\n",
       "1             6  54"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix2 = pd.crosstab(df_from_arr2['Actual'], df_from_arr2['Prediction'])\n",
    "confusion_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8a95a1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [ 54]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2 = np.array(confusion_matrix2)\n",
    "matrix2 = matrix2.reshape(4,1)\n",
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23aee44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN_2 = int(matrix2[0])\n",
    "FP_2 = int(matrix2[1])\n",
    "FN_2 = int(matrix2[2])\n",
    "TP_2 = int(matrix2[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ca3c6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.73684210526315 %\n",
      "Precision 94.73684210526315%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy and Precision\n",
    "print ('Accuracy ' + str(accuracy(TP_2, TN_2, FP_2, FN_2)) + ' %')\n",
    "print('Precision ' + str(precision(TP_2, FP_2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f714f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 90.0%\n",
      "False Negative Rate: 58.333333333333336%\n",
      "True Negative Rate: 97.2972972972973%\n",
      "False Positive Rate: 2.7027027027027026%\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix Performance\n",
    "print('True Positive Rate: ' + str(truePositive(TP_2, FN_2)) + '%')\n",
    "print('False Negative Rate: ' + str(falseNegative(FN_2,FP_2)) + '%')\n",
    "print('True Negative Rate: ' + str(trueNegative(TN_2,FP_2)) + '%')\n",
    "print('False Positive Rate: ' + str(falsePositive(FP_2, TN_2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9cca8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 40 hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e7be4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes2 = 40\n",
    "\n",
    "# Randomised Weights\n",
    "weight1_3 = 2*np.random.random((input_nodes, hidden_nodes2)) - 1\n",
    "weight2_3 = 2*np.random.random((hidden_nodes2, output_nodes)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cb8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Error: 0.5713709046294453\n",
      "Epoch: 1000 Error: 0.05953438163745993\n"
     ]
    }
   ],
   "source": [
    "train_MSE3 = []\n",
    "\n",
    "# Iterates through the network as many times as the epoch is set at\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "#     Forward Propagate\n",
    "    \n",
    "    sum_synapse1 = np.dot(X_train, weight1_3)\n",
    "    hidden_layer = sigmoid(sum_synapse1)\n",
    "        \n",
    "    sum_synapse2 = np.dot(hidden_layer, weight2_3) \n",
    "    output_layer = sigmoid(sum_synapse2)\n",
    "    \n",
    "#     Backward Propagate\n",
    "        \n",
    "    error = y_train-output_layer\n",
    "    \n",
    "    derivative_output = sigmoid_derivative(output_layer)\n",
    "    l2_delta = error * derivative_output\n",
    "    \n",
    "    derivative_hidden = sigmoid_derivative(hidden_layer)\n",
    "    l1_delta = l2_delta.dot(weight2_3.T) * derivative_hidden\n",
    "    \n",
    "    weight2_3 = np.add(weight2_3, hidden_layer.T.dot(l2_delta) * learning_rate)\n",
    "    weight1_3 = np.add(weight1_3, X_train.T.dot(l1_delta) * learning_rate)\n",
    "    \n",
    "#     Error and epoch\n",
    "    \n",
    "    error_average = np.mean(abs(error))\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('Epoch: ' + str(i + 0 ) + ' Error: ' + str(error_average))\n",
    "        train_MSE3.append(error_average)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b0ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "prediction3 = []\n",
    "correct3 = 0\n",
    "\n",
    "# Forward Propagte\n",
    "sum_synapse1 = np.dot(X_test, weight1_3)\n",
    "hidden_layer = sigmoid(sum_synapse1) \n",
    "        \n",
    "sum_synapse2 = np.dot(hidden_layer, weight2_3) \n",
    "output_layer3 = sigmoid(sum_synapse2)\n",
    "\n",
    "for i in range(171):\n",
    "        \n",
    "#         Prediction\n",
    "\n",
    "    if np.all(output_layer3[i] >= 0.5):\n",
    "\n",
    "        predict3= 1\n",
    "    else:\n",
    "        predict3 = 0\n",
    "\n",
    "    if predict3 != y_test[i]:\n",
    "        \n",
    "        correct3 += 0\n",
    "    else:\n",
    "        \n",
    "        correct3 += 1\n",
    "    \n",
    "        \n",
    "        \n",
    "                \n",
    "    prediction3.append(predict3)\n",
    "\n",
    "MeanSquaredError3 = np.square(y_test - prediction3).mean()\n",
    "\n",
    "print(\"Mean Squared Error: \", MeanSquaredError3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE vs Epoch\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Plot showing results from Neural Network')\n",
    "plt.plot(train_MSE3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_arr3 = np.array(prediction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction and Actual Output\n",
    "df_from_arr3 = pd.DataFrame(data=[y_test, prediction_arr3]).T\n",
    "df_from_arr3.rename(columns ={0:'Actual', 1: 'Prediction'}, inplace = True)\n",
    "df_from_arr3.head(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "confusion_matrix3 = pd.crosstab(df_from_arr3['Actual'], df_from_arr2['Prediction'])\n",
    "confusion_matrix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3 = np.array(confusion_matrix3)\n",
    "matrix3 = matrix2.reshape(4,1)\n",
    "matrix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bac193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN_3 = int(matrix2[0])\n",
    "FP_3 = int(matrix2[1])\n",
    "FN_3 = int(matrix2[2])\n",
    "TP_3 = int(matrix2[3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef51de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy and Precision\n",
    "print ('Accuracy ' + str(accuracy(TP_3, TN_3, FP_3, FN_3)) + ' %')\n",
    "print('Precision ' + str(precision(TP_3, FP_3)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Performance\n",
    "print('True Positive Rate: ' + str(truePositive(TP_2, FN_2)) + '%')\n",
    "print('False Negative Rate: ' + str(falseNegative(FN_2,FP_2)) + '%')\n",
    "print('True Negative Rate: ' + str(trueNegative(TN_2,FP_2)) + '%')\n",
    "print('False Positive Rate: ' + str(falsePositive(FP_2, TN_2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three networks' MSE vs Epoch\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Plot showing results from Neural Network')\n",
    "plt.plot(train_MSE, color = 'red', label = '15 Neurons')\n",
    "plt.plot(train_MSE2, color = 'yellow', label = '5 Neurons')\n",
    "plt.plot(train_MSE3, color = 'blue', label = '40 Neurons')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1 = ((correct/len(y_test))*100)\n",
    "accuracy2 = ((correct2/len(y_test))*100)\n",
    "accuracy3 = ((correct3/len(y_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three networks' MSE\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "ax.set_ylabel('MSE ')\n",
    "ax.set_title('Mean Squared Error')\n",
    "neurons = ['15 Neurons', '5 Neurons', '40 Neurons']\n",
    "labels = [MeanSquaredError, MeanSquaredError2, MeanSquaredError3]\n",
    "ax.bar(neurons,labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three networks' Accuracy\n",
    "\n",
    "labels = ['15 Neurons', '5 Neurons', '40 Neurons']\n",
    "accuracy = [accuracy1, accuracy2, accuracy3]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects2 = ax.bar(x + width/2, accuracy, width)\n",
    "\n",
    "ax.set_ylabel('Accuracy %')\n",
    "ax.set_title('Test Accuracy')\n",
    "ax.set_xticks(x, labels)\n",
    "\n",
    "\n",
    "ax.bar_label(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82062d8a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
